{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"experiment_name\": \"tune_lstm_8\",\n",
    "  \"dataset\": {\n",
    "    \"training_ids_file_path\": \"./train_ids.csv\",\n",
    "    \"validation_ids_file_path\": \"./val_ids.csv\",\n",
    "    \"test_ids_file_path\": \"./test_ids.csv\",\n",
    "    \"training_annotation_file_path\": \"./data/annotations/captions_train2014.json\",\n",
    "    \"test_annotation_file_path\": \"./data/annotations/captions_val2014.json\",\n",
    "    \"images_root_dir\": \"./data/images/\",\n",
    "    \"vocabulary_threshold\": 2,\n",
    "    \"img_size\": 256,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_workers\": 4\n",
    "  },\n",
    "  \"experiment\": {\n",
    "    \"num_epochs\": 20,\n",
    "    \"learning_rate\": 1e-4\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"hidden_size\": 640,\n",
    "    \"embedding_size\": 250,\n",
    "    \"model_type\": \"LSTM\",\n",
    "    \"keep_image\": False\n",
    "  },\n",
    "  \"generation\": {\n",
    "    \"max_length\": 20,\n",
    "    \"deterministic\": False,\n",
    "    \"temperature\": 0.1\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = [1e-5, 5e-4, 1e-4]\n",
    "# hidden_size = [256, 512, 768]\n",
    "# embedding_size = [200, 250, 300, 350]\n",
    "\n",
    "lr = [1e-4]\n",
    "hidden_size = [256, 512, 768]\n",
    "embedding_size = [200,250,300,350,400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for i in lr:\n",
    "    for j in hidden_size:\n",
    "        for k in embedding_size:\n",
    "            config['experiment']['learning_rate'] = i\n",
    "            config['model']['hidden_size'] = j\n",
    "            config['model']['embedding_size'] = k\n",
    "            config['experiment_name'] = f'lstm_{i}_{j}_{k}'\n",
    "            jobs.append(f'lstm_{i}_{j}_{k}')\n",
    "            with open(f'./model_configs/lstm_{i}_{j}_{k}.json', 'w') as f:\n",
    "                json.dump(config, f, indent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_0.0001_256_150\n",
      "Running Experiment:  lstm_0.0001_256_150\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "lstm_0.0001_256_300creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [03:01<57:23, 181.23s/it]\n",
      " 10%|█         | 2/20 [06:01<54:14, 180.79s/it]\n",
      " 15%|█▌        | 3/20 [09:02<51:11, 180.70s/it]\n",
      " 20%|██        | 4/20 [12:02<48:08, 180.53s/it]\n",
      " 25%|██▌       | 5/20 [15:02<45:05, 180.40s/it]\n",
      " 30%|███       | 6/20 [17:53<41:20, 177.19s/it]\n",
      " 35%|███▌      | 7/20 [20:43<37:52, 174.77s/it]\n",
      " 40%|████      | 8/20 [23:34<34:43, 173.59s/it]\n",
      " 45%|████▌     | 9/20 [26:25<31:41, 172.84s/it]\n",
      " 50%|█████     | 10/20 [29:16<28:42, 172.27s/it]\n",
      " 55%|█████▌    | 11/20 [32:07<25:47, 171.95s/it]\n",
      " 55%|█████▌    | 11/20 [34:57<28:35, 190.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 3.2211302483030653, Val Loss: 2.487935478870685, Took 0:03:01.043958, ETA: 0:57:19.835202\n",
      "\n",
      "Epoch: 2, Train Loss: 2.398139764106325, Val Loss: 2.243441291955801, Took 0:03:00.290088, ETA: 0:54:05.221584\n",
      "\n",
      "Epoch: 3, Train Loss: 2.19381634355103, Val Loss: 2.117718502191397, Took 0:03:00.391231, ETA: 0:51:06.650927\n",
      "\n",
      "Epoch: 4, Train Loss: 2.0553141417421497, Val Loss: 1.9833328347939712, Took 0:03:00.082632, ETA: 0:48:01.322112\n",
      "\n",
      "Epoch: 5, Train Loss: 1.9277896521940763, Val Loss: 1.8843807252553793, Took 0:02:59.976045, ETA: 0:44:59.640675\n",
      "\n",
      "Epoch: 6, Train Loss: 1.8210675645283876, Val Loss: 1.855053040614495, Took 0:02:50.768978, ETA: 0:39:50.765692\n",
      "\n",
      "Epoch: 7, Train Loss: 1.7599997122400308, Val Loss: 1.7603158469383533, Took 0:02:49.601073, ETA: 0:36:44.813949\n",
      "\n",
      "Epoch: 8, Train Loss: 1.7036529053434282, Val Loss: 1.7253902054750003, Took 0:02:50.884449, ETA: 0:34:10.613388\n",
      "\n",
      "Epoch: 9, Train Loss: 1.6590536276158345, Val Loss: 1.6773266411744632, Took 0:02:50.988766, ETA: 0:31:20.876426\n",
      "\n",
      "Epoch: 10, Train Loss: 1.6194798979636427, Val Loss: 1.6636204201441545, Took 0:02:50.814540, ETA: 0:28:28.145400\n",
      "\n",
      "Epoch: 11, Train Loss: 1.5751441136961843, Val Loss: 1.6079050852702215, Took 0:02:51.044089, ETA: 0:25:39.396801\n",
      "\n",
      "Test Performance: Loss: 1.6130138250107462, Perplexity: 5.0179115688989855, Bleu1: 65.56190435972599, Bleu4: 6.724425716063331\n",
      "Running Experiment:  lstm_0.0001_256_300\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 3.170864356126908, Val Loss: 2.492770692935357, Took 0:02:52.519390, ETA: 0:54:37.868410\n",
      "\n",
      "Epoch: 2, Train Loss: 2.351533868537952, Val Loss: 2.227574336528778, Took 0:02:50.011856, ETA: 0:51:00.213408\n",
      "\n",
      "Epoch: 3, Train Loss: 2.145777536973421, Val Loss: 2.089100701075334, Took 0:02:50.724987, ETA: 0:48:22.324779\n",
      "\n",
      "Epoch: 4, Train Loss: 2.0041795760265235, Val Loss: 1.9535663049954635, Took 0:02:50.265257, ETA: 0:45:24.244112\n",
      "\n",
      "Epoch: 5, Train Loss: 1.8857728166641596, Val Loss: 1.8434014815550583, Took 0:02:50.091632, ETA: 0:42:31.374480\n",
      "\n",
      "Epoch: 6, Train Loss: 1.7852428498697894, Val Loss: 1.7623738976625296, Took 0:02:49.792853, ETA: 0:39:37.099942\n",
      "\n",
      "Epoch: 7, Train Loss: 1.7092131710359466, Val Loss: 1.7319408297538756, Took 0:02:49.848798, ETA: 0:36:48.034374\n",
      "\n",
      "Epoch: 8, Train Loss: 1.6414805565780837, Val Loss: 1.6667067284767445, Took 0:02:49.683793, ETA: 0:33:56.205516\n",
      "lstm_0.0001_256_350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [02:52<54:41, 172.73s/it]\n",
      " 10%|█         | 2/20 [05:42<51:22, 171.26s/it]\n",
      " 15%|█▌        | 3/20 [08:33<48:29, 171.12s/it]\n",
      " 20%|██        | 4/20 [11:24<45:33, 170.87s/it]\n",
      " 25%|██▌       | 5/20 [14:14<42:40, 170.67s/it]\n",
      " 30%|███       | 6/20 [17:04<39:46, 170.45s/it]\n",
      " 35%|███▌      | 7/20 [19:54<36:54, 170.33s/it]\n",
      " 40%|████      | 8/20 [22:44<34:02, 170.19s/it]\n",
      " 45%|████▌     | 9/20 [25:35<31:14, 170.43s/it]\n",
      " 50%|█████     | 10/20 [28:26<28:26, 170.61s/it]\n",
      " 55%|█████▌    | 11/20 [31:17<25:34, 170.54s/it]\n",
      " 60%|██████    | 12/20 [34:06<22:42, 170.30s/it]\n",
      " 65%|██████▌   | 13/20 [36:56<19:51, 170.15s/it]\n",
      " 65%|██████▌   | 13/20 [39:47<21:25, 183.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, Train Loss: 1.5953165186832903, Val Loss: 1.638835384295537, Took 0:02:50.722771, ETA: 0:31:17.950481\n",
      "\n",
      "Epoch: 10, Train Loss: 1.562016159628594, Val Loss: 1.6128206349336185, Took 0:02:50.795487, ETA: 0:28:27.954870\n",
      "\n",
      "Epoch: 11, Train Loss: 1.525120164191774, Val Loss: 1.586419818493036, Took 0:02:50.134596, ETA: 0:25:31.211364\n",
      "\n",
      "Epoch: 12, Train Loss: 1.4934548911618573, Val Loss: 1.563285488807238, Took 0:02:49.548576, ETA: 0:22:36.388608\n",
      "\n",
      "Epoch: 13, Train Loss: 1.470839822036514, Val Loss: 1.5464330242230342, Took 0:02:49.569885, ETA: 0:19:46.989195\n",
      "\n",
      "Test Performance: Loss: 1.5340756129711233, Perplexity: 4.637037131212729, Bleu1: 66.34517985400277, Bleu4: 7.239726986536064\n",
      "Running Experiment:  lstm_0.0001_256_350\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 3.1442260364606147, Val Loss: 2.450091329904703, Took 0:02:51.378246, ETA: 0:54:16.186674\n",
      "\n",
      "Epoch: 2, Train Loss: 2.308913068914618, Val Loss: 2.1883284082779517, Took 0:02:49.128945, ETA: 0:50:44.321010\n",
      "\n",
      "Epoch: 3, Train Loss: 2.114205855719521, Val Loss: 2.031355203115023, Took 0:02:50.218936, ETA: 0:48:13.721912\n",
      "\n",
      "Epoch: 4, Train Loss: 1.9669184283125554, Val Loss: 1.9166658497773683, Took 0:02:50.637988, ETA: 0:45:30.207808\n",
      "\n",
      "Epoch: 5, Train Loss: 1.8330167427083452, Val Loss: 1.7965699585584494, Took 0:02:49.968679, ETA: 0:42:29.530185\n",
      "\n",
      "Epoch: 6, Train Loss: 1.74022947826099, Val Loss: 1.729249525987185, Took 0:02:50.406190, ETA: 0:39:45.686660\n",
      "\n",
      "Epoch: 7, Train Loss: 1.6710972867810163, Val Loss: 1.6998750865459442, Took 0:02:50.937788, ETA: 0:37:02.191244\n",
      "\n",
      "Epoch: 8, Train Loss: 1.6067551458854021, Val Loss: 1.638081385080631, Took 0:02:49.198161, ETA: 0:33:50.377932\n",
      "\n",
      "Epoch: 9, Train Loss: 1.558005154132843, Val Loss: 1.6158597776523003, Took 0:02:50.743692, ETA: 0:31:18.180612\n",
      "\n",
      "Epoch: 10, Train Loss: 1.5278769083289119, Val Loss: 1.585663340641902, Took 0:02:50.999158, ETA: 0:28:29.991580\n",
      "\n",
      "Epoch: 11, Train Loss: 1.4946408474905808, Val Loss: 1.5770299223753121, Took 0:02:50.169058, ETA: 0:25:31.521522\n",
      "\n",
      "Epoch: 12, Train Loss: 1.4731406052736766, Val Loss: 1.5450834553975326, Took 0:02:49.619926, ETA: 0:22:36.959408\n",
      "\n",
      "Epoch: 13, Train Loss: 1.4479884862899781, Val Loss: 1.538853312455691, Took 0:02:51.077093, ETA: 0:19:57.539651\n",
      "\n",
      "Epoch: 14, Train Loss: 1.4112986380450203, Val Loss: 1.513285915209697, Took 0:02:51.348637, ETA: 0:17:08.091822\n",
      "\n",
      "Epoch: 15, Train Loss: 1.3955148487643623, Val Loss: 1.5082757317102873, Took 0:02:51.812294, ETA: 0:14:19.061470\n",
      "\n",
      "Epoch: 16, Train Loss: 1.3714013091995991, Val Loss: 1.488594594368568, Took 0:02:50.113502, ETA: 0:11:20.454008\n",
      "\n",
      "Test Performance: Loss: 1.4974856668330254, Perplexity: 4.470434765329645, Bleu1: 67.01422556929381, Bleu4: 7.489360623076026\n",
      "lstm_0.0001_512_150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [02:51<54:20, 171.60s/it]\n",
      " 10%|█         | 2/20 [05:40<51:05, 170.28s/it]\n",
      " 15%|█▌        | 3/20 [08:31<48:16, 170.36s/it]\n",
      " 20%|██        | 4/20 [11:22<45:29, 170.57s/it]\n",
      " 25%|██▌       | 5/20 [14:12<42:36, 170.44s/it]\n",
      " 30%|███       | 6/20 [17:03<39:47, 170.51s/it]\n",
      " 35%|███▌      | 7/20 [19:54<36:59, 170.73s/it]\n",
      " 40%|████      | 8/20 [22:43<34:03, 170.32s/it]\n",
      " 45%|████▌     | 9/20 [25:34<31:15, 170.53s/it]\n",
      " 50%|█████     | 10/20 [28:26<28:27, 170.75s/it]\n",
      " 55%|█████▌    | 11/20 [31:16<25:35, 170.65s/it]\n",
      " 60%|██████    | 12/20 [34:06<22:43, 170.40s/it]\n",
      " 65%|██████▌   | 13/20 [36:57<19:54, 170.68s/it]\n",
      " 70%|███████   | 14/20 [39:49<17:05, 170.96s/it]\n",
      " 75%|███████▌  | 15/20 [42:41<14:16, 171.29s/it]\n",
      " 80%|████████  | 16/20 [45:31<11:24, 171.00s/it]\n",
      " 80%|████████  | 16/20 [48:22<12:05, 181.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment:  lstm_0.0001_512_150\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 2.8754082915097348, Val Loss: 2.338657364478478, Took 0:02:52.753659, ETA: 0:54:42.319521\n",
      "\n",
      "Epoch: 2, Train Loss: 2.186862722742711, Val Loss: 2.0685746302971473, Took 0:02:48.626978, ETA: 0:50:35.285604\n",
      "\n",
      "Epoch: 3, Train Loss: 1.9566550103379934, Val Loss: 1.9075456229540018, Took 0:02:49.480992, ETA: 0:48:01.176864\n",
      "\n",
      "Epoch: 4, Train Loss: 1.8056848922000934, Val Loss: 1.764164804495298, Took 0:02:50.638175, ETA: 0:45:30.210800\n",
      "\n",
      "Epoch: 5, Train Loss: 1.7059009611350784, Val Loss: 1.700932798935817, Took 0:02:50.907762, ETA: 0:42:43.616430\n",
      "\n",
      "Epoch: 6, Train Loss: 1.6247747430985577, Val Loss: 1.6417173335185418, Took 0:02:50.803115, ETA: 0:39:51.243610\n",
      "\n",
      "Epoch: 7, Train Loss: 1.5731217916942972, Val Loss: 1.61339757671723, Took 0:02:50.418810, ETA: 0:36:55.444530\n",
      "\n",
      "Epoch: 8, Train Loss: 1.5239062352753505, Val Loss: 1.574012869137984, Took 0:02:50.434113, ETA: 0:34:05.209356\n",
      "\n",
      "Epoch: 9, Train Loss: 1.4865157692217519, Val Loss: 1.5543505700734945, Took 0:02:50.308189, ETA: 0:31:13.390079\n",
      "\n",
      "Epoch: 10, Train Loss: 1.446231869566594, Val Loss: 1.5212390376971319, Took 0:02:50.370519, ETA: 0:28:23.705190\n",
      "\n",
      "Test Performance: Loss: 1.515308020723627, Perplexity: 4.550822658672563, Bleu1: 66.37351001867715, Bleu4: 7.438872975880954\n",
      "lstm_0.0001_512_300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [02:53<54:47, 173.01s/it]\n",
      " 10%|█         | 2/20 [05:41<51:10, 170.59s/it]\n",
      " 15%|█▌        | 3/20 [08:31<48:13, 170.21s/it]\n",
      " 20%|██        | 4/20 [11:22<45:27, 170.49s/it]\n",
      " 25%|██▌       | 5/20 [14:13<42:41, 170.74s/it]\n",
      " 30%|███       | 6/20 [17:04<39:51, 170.86s/it]\n",
      " 35%|███▌      | 7/20 [19:55<37:00, 170.80s/it]\n",
      " 40%|████      | 8/20 [22:46<34:09, 170.77s/it]\n",
      " 45%|████▌     | 9/20 [25:36<31:17, 170.71s/it]\n",
      " 50%|█████     | 10/20 [28:27<28:26, 170.69s/it]\n",
      " 50%|█████     | 10/20 [31:18<31:18, 187.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment:  lstm_0.0001_512_300\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 2.7809055438880756, Val Loss: 2.248881721496582, Took 0:02:53.024214, ETA: 0:54:47.460066\n",
      "\n",
      "Epoch: 2, Train Loss: 2.0907497230517507, Val Loss: 1.9592763786132519, Took 0:02:49.608083, ETA: 0:50:52.945494\n",
      "\n",
      "Epoch: 3, Train Loss: 1.8546719599179444, Val Loss: 1.8173916358214157, Took 0:02:50.672067, ETA: 0:48:21.425139\n",
      "\n",
      "Epoch: 4, Train Loss: 1.7114147429814155, Val Loss: 1.6930014257247632, Took 0:02:50.620973, ETA: 0:45:29.935568\n",
      "\n",
      "Epoch: 5, Train Loss: 1.6185971037001057, Val Loss: 1.6342548897633187, Took 0:02:50.466278, ETA: 0:42:36.994170\n",
      "\n",
      "Epoch: 6, Train Loss: 1.551883055723788, Val Loss: 1.5745248482777523, Took 0:02:50.531957, ETA: 0:39:47.447398\n",
      "\n",
      "Epoch: 7, Train Loss: 1.495100343790177, Val Loss: 1.5570479640593895, Took 0:02:50.171486, ETA: 0:36:52.229318\n",
      "\n",
      "Epoch: 8, Train Loss: 1.4471434264735603, Val Loss: 1.5254970394648038, Took 0:02:49.417967, ETA: 0:33:53.015604\n",
      "\n",
      "Epoch: 9, Train Loss: 1.412996760356068, Val Loss: 1.4825988810796005, Took 0:02:51.061853, ETA: 0:31:21.680383\n",
      "\n",
      "Test Performance: Loss: 1.4750807095081249, Perplexity: 4.371388571313888, Bleu1: 66.67049022327905, Bleu4: 7.615216889184305\n",
      "lstm_0.0001_512_350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [02:53<54:53, 173.32s/it]\n",
      " 10%|█         | 2/20 [05:43<51:23, 171.32s/it]\n",
      " 15%|█▌        | 3/20 [08:34<48:29, 171.16s/it]\n",
      " 20%|██        | 4/20 [11:25<45:37, 171.07s/it]\n",
      " 25%|██▌       | 5/20 [14:15<42:44, 170.96s/it]\n",
      " 30%|███       | 6/20 [17:06<39:52, 170.92s/it]\n",
      " 35%|███▌      | 7/20 [19:57<37:00, 170.78s/it]\n",
      " 40%|████      | 8/20 [22:46<34:05, 170.44s/it]\n",
      " 45%|████▌     | 9/20 [25:38<31:18, 170.73s/it]\n",
      " 45%|████▌     | 9/20 [28:28<34:47, 189.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment:  lstm_0.0001_512_350\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 2.757952074278066, Val Loss: 2.235782340856699, Took 0:02:52.212905, ETA: 0:54:32.045195\n",
      "\n",
      "Epoch: 2, Train Loss: 2.055913459384902, Val Loss: 1.9290090583837949, Took 0:02:50.272410, ETA: 0:51:04.903380\n",
      "\n",
      "Epoch: 3, Train Loss: 1.824078165001112, Val Loss: 1.7620223137048574, Took 0:02:50.601597, ETA: 0:48:20.227149\n",
      "\n",
      "Epoch: 4, Train Loss: 1.6886385284779921, Val Loss: 1.6646494581149174, Took 0:02:50.608128, ETA: 0:45:29.730048\n",
      "\n",
      "Epoch: 5, Train Loss: 1.5943094020749367, Val Loss: 1.6159843802452087, Took 0:02:50.263312, ETA: 0:42:33.949680\n",
      "\n",
      "Epoch: 6, Train Loss: 1.5285965757820228, Val Loss: 1.5786405379955586, Took 0:02:49.555806, ETA: 0:39:33.781284\n",
      "\n",
      "Epoch: 7, Train Loss: 1.4791488151181922, Val Loss: 1.5349383771419525, Took 0:02:50.070534, ETA: 0:36:50.916942\n",
      "\n",
      "Epoch: 8, Train Loss: 1.4273483043064887, Val Loss: 1.5172771334648132, Took 0:02:49.787208, ETA: 0:33:57.446496\n",
      "\n",
      "Epoch: 9, Train Loss: 1.3905881425341824, Val Loss: 1.4768950819969178, Took 0:02:50.809247, ETA: 0:31:18.901717\n",
      "\n",
      "Epoch: 10, Train Loss: 1.357556126864683, Val Loss: 1.4734572942440327, Took 0:02:49.915281, ETA: 0:28:19.152810\n",
      "\n",
      "Test Performance: Loss: 1.4612037894573617, Perplexity: 4.31114611818401, Bleu1: 67.12352361630892, Bleu4: 8.044495933369438\n",
      "lstm_0.0001_768_150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [02:52<54:37, 172.51s/it]\n",
      " 10%|█         | 2/20 [05:43<51:24, 171.38s/it]\n",
      " 15%|█▌        | 3/20 [08:34<48:29, 171.17s/it]\n",
      " 20%|██        | 4/20 [11:24<45:37, 171.08s/it]\n",
      " 25%|██▌       | 5/20 [14:15<42:43, 170.90s/it]\n",
      " 30%|███       | 6/20 [17:05<39:47, 170.55s/it]\n",
      " 35%|███▌      | 7/20 [19:55<36:56, 170.50s/it]\n",
      " 40%|████      | 8/20 [22:45<34:04, 170.38s/it]\n",
      " 45%|████▌     | 9/20 [25:37<31:16, 170.61s/it]\n",
      " 50%|█████     | 10/20 [28:27<28:24, 170.49s/it]\n",
      " 50%|█████     | 10/20 [31:17<31:17, 187.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment:  lstm_0.0001_768_150\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 2.697378994671572, Val Loss: 2.2163918486008276, Took 0:02:53.629993, ETA: 0:54:58.969867\n",
      "\n",
      "Epoch: 2, Train Loss: 2.0526265713278318, Val Loss: 1.9106967183259818, Took 0:02:50.859125, ETA: 0:51:15.464250\n",
      "\n",
      "Epoch: 3, Train Loss: 1.823530232292388, Val Loss: 1.7751436036366683, Took 0:02:51.113200, ETA: 0:48:28.924400\n",
      "\n",
      "Epoch: 4, Train Loss: 1.699073825169019, Val Loss: 1.684227942961913, Took 0:02:50.122450, ETA: 0:45:21.959200\n",
      "\n",
      "Epoch: 5, Train Loss: 1.6012856305924608, Val Loss: 1.6158988168606392, Took 0:02:49.943910, ETA: 0:42:29.158650\n",
      "\n",
      "Epoch: 6, Train Loss: 1.5389717762562338, Val Loss: 1.5772495554043697, Took 0:02:50.973501, ETA: 0:39:53.629014\n",
      "\n",
      "Epoch: 7, Train Loss: 1.4800134446999547, Val Loss: 1.5456606195523188, Took 0:02:49.948665, ETA: 0:36:49.332645\n",
      "\n",
      "Epoch: 8, Train Loss: 1.4336873576876432, Val Loss: 1.5256812425760122, Took 0:02:49.895217, ETA: 0:33:58.742604\n",
      "\n",
      "Epoch: 9, Train Loss: 1.3928634596996552, Val Loss: 1.489126855134964, Took 0:02:50.237626, ETA: 0:31:12.613886\n",
      "\n",
      "Epoch: 10, Train Loss: 1.3587672492465237, Val Loss: 1.4745550843385549, Took 0:02:50.146018, ETA: 0:28:21.460180\n",
      "\n",
      "Epoch: 11, Train Loss: 1.3255726636735155, Val Loss: 1.451191551410235, Took 0:02:51.360537, ETA: 0:25:42.244833\n",
      "\n",
      "Test Performance: Loss: 1.4705567078387483, Perplexity: 4.351657068448759, Bleu1: 66.78727716404454, Bleu4: 7.981512650524049\n",
      "lstm_0.0001_768_300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [02:53<55:05, 173.99s/it]\n",
      " 10%|█         | 2/20 [05:45<51:42, 172.37s/it]\n",
      " 15%|█▌        | 3/20 [08:36<48:43, 171.98s/it]\n",
      " 20%|██        | 4/20 [11:27<45:42, 171.39s/it]\n",
      " 25%|██▌       | 5/20 [14:17<42:45, 171.01s/it]\n",
      " 30%|███       | 6/20 [17:08<39:55, 171.13s/it]\n",
      " 35%|███▌      | 7/20 [19:59<37:01, 170.87s/it]\n",
      " 40%|████      | 8/20 [22:49<34:08, 170.68s/it]\n",
      " 45%|████▌     | 9/20 [25:40<31:17, 170.66s/it]\n",
      " 50%|█████     | 10/20 [28:30<28:26, 170.62s/it]\n",
      " 55%|█████▌    | 11/20 [31:22<25:38, 170.96s/it]\n",
      " 55%|█████▌    | 11/20 [34:13<28:00, 186.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment:  lstm_0.0001_768_300\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "lstm_0.0001_768_350\n",
      "Done (t=0.18s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [02:52<54:41, 172.69s/it]\n",
      " 10%|█         | 2/20 [05:44<51:35, 171.96s/it]\n",
      " 15%|█▌        | 3/20 [08:35<48:39, 171.76s/it]\n",
      " 20%|██        | 4/20 [11:35<46:37, 174.87s/it]\n",
      " 25%|██▌       | 5/20 [14:37<44:23, 177.57s/it]\n",
      " 30%|███       | 6/20 [17:38<41:41, 178.70s/it]\n",
      " 30%|███       | 6/20 [20:39<48:11, 206.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 2.610214422598417, Val Loss: 2.1159179696669947, Took 0:02:52.298265, ETA: 0:54:33.667035\n",
      "\n",
      "Epoch: 2, Train Loss: 1.95404584474318, Val Loss: 1.8380959309064424, Took 0:02:51.049127, ETA: 0:51:18.884286\n",
      "\n",
      "Epoch: 3, Train Loss: 1.7216403263832878, Val Loss: 1.6868922435320342, Took 0:02:51.105848, ETA: 0:48:28.799416\n",
      "\n",
      "Epoch: 4, Train Loss: 1.6013239896348617, Val Loss: 1.5931783066346095, Took 0:02:59.218001, ETA: 0:47:47.488016\n",
      "\n",
      "Epoch: 5, Train Loss: 1.5235392725007217, Val Loss: 1.5441892761450546, Took 0:03:01.941455, ETA: 0:45:29.121825\n",
      "\n",
      "Epoch: 6, Train Loss: 1.4586751400656965, Val Loss: 1.49426612670605, Took 0:03:00.487465, ETA: 0:42:06.824510\n",
      "\n",
      "Test Performance: Loss: 1.4894609119029756, Perplexity: 4.43470417825359, Bleu1: 66.53445962049052, Bleu4: 7.539107353740832\n",
      "Running Experiment:  lstm_0.0001_768_350\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Epoch: 1, Train Loss: 2.624079040396367, Val Loss: 2.105239947942587, Took 0:03:04.671275, ETA: 0:58:28.754225\n",
      "\n",
      "Epoch: 2, Train Loss: 1.9489254962221236, Val Loss: 1.8361156330658839, Took 0:03:00.887467, ETA: 0:54:15.974406\n",
      "\n",
      "Epoch: 3, Train Loss: 1.720263416777353, Val Loss: 1.6829853667662693, Took 0:02:50.427608, ETA: 0:48:17.269336\n",
      "\n",
      "Epoch: 4, Train Loss: 1.6004338600093202, Val Loss: 1.592591319175867, Took 0:02:50.663775, ETA: 0:45:30.620400\n",
      "\n",
      "Epoch: 5, Train Loss: 1.510583874391384, Val Loss: 1.5510971697477194, Took 0:02:51.642296, ETA: 0:42:54.634440\n",
      "\n",
      "Epoch: 6, Train Loss: 1.441612997484821, Val Loss: 1.5052976823770083, Took 0:02:52.168925, ETA: 0:40:10.364950\n",
      "\n",
      "Epoch: 7, Train Loss: 1.3889077636305354, Val Loss: 1.4848699721006247, Took 0:02:51.505117, ETA: 0:37:09.566521\n",
      "\n",
      "Epoch: 8, Train Loss: 1.3474326888890737, Val Loss: 1.4597650142816396, Took 0:02:50.852824, ETA: 0:34:10.233888\n",
      "\n",
      "Epoch: 9, Train Loss: 1.3065664461242283, Val Loss: 1.4497789891866537, Took 0:02:51.159975, ETA: 0:31:22.759725\n",
      "\n",
      "Epoch: 10, Train Loss: 1.266544779278178, Val Loss: 1.4398959609178397, Took 0:02:50.726951, ETA: 0:28:27.269510\n",
      "\n",
      "Epoch: 11, Train Loss: 1.232073544381514, Val Loss: 1.430453783273697, Took 0:02:51.635110, ETA: 0:25:44.715990\n",
      "\n",
      "Epoch: 12, Train Loss: 1.199197467611583, Val Loss: 1.4277419489163619, Took 0:02:52.699791, ETA: 0:23:01.598328\n",
      "\n",
      "Test Performance: Loss: 1.4344153363653953, Perplexity: 4.197190346718783, Bleu1: 67.77495522450724, Bleu4: 8.967362508454396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [03:05<58:36, 185.08s/it]\n",
      " 10%|█         | 2/20 [06:06<54:51, 182.87s/it]\n",
      " 15%|█▌        | 3/20 [08:57<50:15, 177.38s/it]\n",
      " 20%|██        | 4/20 [11:48<46:38, 174.89s/it]\n",
      " 25%|██▌       | 5/20 [14:40<43:28, 173.88s/it]\n",
      " 30%|███       | 6/20 [17:32<40:28, 173.44s/it]\n",
      " 35%|███▌      | 7/20 [20:24<37:28, 172.95s/it]\n",
      " 40%|████      | 8/20 [23:16<34:28, 172.42s/it]\n",
      " 45%|████▌     | 9/20 [26:07<31:33, 172.16s/it]\n",
      " 50%|█████     | 10/20 [28:58<28:38, 171.86s/it]\n",
      " 55%|█████▌    | 11/20 [31:51<25:47, 171.92s/it]\n",
      " 60%|██████    | 12/20 [34:44<22:58, 172.29s/it]\n",
      " 60%|██████    | 12/20 [37:45<25:10, 188.76s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# jobs = os.listdir('./model_configs/')\n",
    "for job in jobs:\n",
    "    if job.startswith('lstm'):\n",
    "        print(job)\n",
    "        !python main.py {job}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a3f5f48057ce4acc7dea638153994ce8b5856197635dcf2b55bc675f9675242"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
